@article{bahdanau2014neural,
  title = {Neural Machine Translation by Jointly Learning to Align and Translate
           },
  author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
  year = {2014},
  eprint = {1409.0473},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/1409.0473},
}

@inproceedings{vaswani2017attention,
  title = {Attention Is All You Need},
  author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit
            and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia
            Polosukhin},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
  pages = {5998--6008},
  year = {2017},
  url = {https://papers.nips.cc/paper/7181-attention-is-all-you-need},
}

@article{su2021roformer,
  title = {RoFormer: Enhanced Transformer with Rotary Position Embedding},
  author = {Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen
            and Yunfeng Liu},
  year = {2021},
  eprint = {2104.09864},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/2104.09864},
}

@inproceedings{dao2022flashattention,
  title = {FlashAttention: Fast and Memory-Efficient Exact Attention with
           IO-Awareness},
  author = {Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and
            Christopher R\'{e}},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {16344--16359},
  year = {2022},
  url = {https://arxiv.org/abs/2205.14135},
}

@article{dao2023flashattention2,
  title = {FlashAttention-2: Faster Attention with Better Parallelism and Work
           Partitioning},
  author = {Tri Dao},
  year = {2023},
  eprint = {2307.08691},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url = {https://arxiv.org/abs/2307.08691},
}

@article{harris1954distributional,
  title = {Distributional Structure},
  author = {Zellig S. Harris},
  journal = {Word},
  volume = {10},
  number = {2-3},
  pages = {146--162},
  year = {1954},
}

@article{jones1972statistical,
  title = {A Statistical Interpretation of Term Specificity and Its Application
           in Retrieval},
  author = {Karen Sp\"{a}rck Jones},
  journal = {Journal of Documentation},
  volume = {28},
  number = {1},
  pages = {11--21},
  year = {1972},
}

@book{jurafsky2009speech,
  title = {Speech and Language Processing},
  author = {Daniel Jurafsky and James H. Martin},
  edition = {2nd},
  publisher = {Pearson},
  year = {2009},
}

@book{manning2008introduction,
  title = {Introduction to Information Retrieval},
  author = {Christopher D. Manning and Prabhakar Raghavan and Hinrich Sch\"{u}
            tze},
  publisher = {Cambridge University Press},
  year = {2008},
}

@article{hopfield1982neural,
  title = {Neural Networks and Physical Systems with Emergent Collective
           Computational Abilities},
  author = {John J. Hopfield},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {79},
  number = {8},
  pages = {2554--2558},
  year = {1982},
}

@article{rumelhart1986learning,
  title = {Learning Representations by Back-Propagating Errors},
  author = {David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  journal = {Nature},
  volume = {323},
  number = {6088},
  pages = {533--536},
  year = {1986},
}

@article{elman1990finding,
  title = {Finding Structure in Time},
  author = {Jeffrey L. Elman},
  journal = {Cognitive Science},
  volume = {14},
  number = {2},
  pages = {179--211},
  year = {1990},
}

@article{hochreiter1997long,
  title = {Long Short-Term Memory},
  author = {Sepp Hochreiter and J\"{u}rgen Schmidhuber},
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  year = {1997},
}

@article{greff2017lstm,
  title = {LSTM: A Search Space Odyssey},
  author = {Klaus Greff and Rupesh K. Srivastava and Jan Koutn\'{i}k and Bas R.
            Steunebrink and J\"{u}rgen Schmidhuber},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {28},
  number = {10},
  pages = {2222--2232},
  year = {2017},
}

@article{bengio2003neural,
  title = {A Neural Probabilistic Language Model},
  author = {Yoshua Bengio and R\'{e}jean Ducharme and Pascal Vincent and
            Christian Jauvin},
  journal = {Journal of Machine Learning Research},
  volume = {3},
  pages = {1137--1155},
  year = {2003},
}

@misc{mikolov2013efficient,
  title = {Efficient Estimation of Word Representations in Vector Space},
  author = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  year = {2013},
  eprint = {1301.3781},
  archivePrefix = {arXiv},
  primaryClass = {cs.CL},
  url = {https://arxiv.org/abs/1301.3781},
}

@inproceedings{mikolov2013distributed,
  title = {Distributed Representations of Words and Phrases and Their
           Compositionality},
  author = {Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg S. Corrado
            and Jeff Dean},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {26},
  pages = {3111--3119},
  year = {2013},
}

@inproceedings{mikolov2013linguistic,
  title = {Linguistic Regularities in Continuous Space Word Representations},
  author = {Tomas Mikolov and Wen-tau Yih and Geoffrey Zweig},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter
               of the Association for Computational Linguistics},
  pages = {746--751},
  year = {2013},
}

@inproceedings{sutskever2014sequence,
  title = {Sequence to Sequence Learning with Neural Networks},
  author = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {27},
  pages = {3104--3112},
  year = {2014},
}

@inproceedings{cho2014learning,
  title = {Learning Phrase Representations using RNN Encoder-Decoder for
           Statistical Machine Translation},
  author = {Kyunghyun Cho and Bart Van Merri\"{e}nboer and Caglar Gulcehre and
            Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua
            Bengio},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in
               Natural Language Processing},
  pages = {1724--1734},
  year = {2014},
}

@inproceedings{luong2015effective,
  title = {Effective Approaches to Attention-based Neural Machine Translation},
  author = {Minh-Thang Luong and Hieu Pham and Christopher D. Manning},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in
               Natural Language Processing},
  pages = {1412--1421},
  year = {2015},
}

@inproceedings{parikh2016decomposable,
  title = {A Decomposable Attention Model for Natural Language Inference},
  author = {Ankur Parikh and Oscar T\"{a}ckstr\"{o}m and Dipanjan Das and Jakob
            Uszkoreit},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in
               Natural Language Processing},
  pages = {2249--2255},
  year = {2016},
}

@inproceedings{cheng2016long,
  title = {Long Short-Term Memory-Networks for Machine Reading},
  author = {Jianpeng Cheng and Li Dong and Mirella Lapata},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in
               Natural Language Processing},
  pages = {551--561},
  year = {2016},
}

@inproceedings{lin2017structured,
  title = {A Structured Self-Attentive Sentence Embedding},
  author = {Zhouhan Lin and Minwei Feng and Cicero Nogueira dos Santos and Mo Yu
            and Bing Xiang and Bowen Zhou and Yoshua Bengio},
  booktitle = {International Conference on Learning Representations},
  year = {2017},
}

@inproceedings{shaw2018self,
  title = {Self-Attention with Relative Position Representations},
  author = {Peter Shaw and Jakob Uszkoreit and Ashish Vaswani},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter
               of the Association for Computational Linguistics},
  pages = {464--468},
  year = {2018},
}

@techreport{radford2018improving,
  title = {Improving Language Understanding by Generative Pre-Training},
  author = {Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya
            Sutskever},
  institution = {OpenAI},
  year = {2018},
  url = {https://openai.com/research/language-unsupervised},
}

@techreport{radford2019language,
  title = {Language Models are Unsupervised Multitask Learners},
  author = {Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario
            Amodei and Ilya Sutskever},
  institution = {OpenAI},
  year = {2019},
  url = {https://openai.com/research/better-language-models},
}

@inproceedings{brown2020language,
  title = {Language Models are Few-Shot Learners},
  author = {Tom Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and
            Jared D. Kaplan and Prafulla Dhariwal and Arvind Neelakantan and
            Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal
            and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and
            Rewon Child and Aditya Ramesh and Daniel Ziegler and Jeffrey Wu and
            Clemens Winter and Chris Hesse and Mark Chen and Eric Sigler and
            Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and
            Christopher Berner and Sam McCandlish and Alec Radford and Ilya
            Sutskever and Dario Amodei},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {1877--1901},
  year = {2020},
}

@inproceedings{devlin2019bert,
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language
           Understanding},
  author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina
            Toutanova},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter
               of the Association for Computational Linguistics},
  pages = {4171--4186},
  year = {2019},
}

@article{tay2020efficient,
  title = {Efficient Transformers: A Survey},
  author = {Yi Tay and Mostafa Dehghani and Dara Bahri and Donald Metzler},
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {6},
  pages = {1--28},
  year = {2020},
}

@inproceedings{ivanov2021data,
  title = {Data Movement Is All You Need: A Case Study on Optimizing
           Transformers},
  author = {Andrei Ivanov and Nikoli Dryden and Tal Ben-Nun and Shigang Li and
            Torsten Hoefler},
  booktitle = {Proceedings of Machine Learning and Systems},
  volume = {3},
  pages = {711--732},
  year = {2021},
}

@inproceedings{tancik2020fourier,
  title = {Fourier Features Let Networks Learn High Frequency Functions in Low
           Dimensional Domains},
  author = {Matthew Tancik and Pratul Srinivasan and Ben Mildenhall and Sara
            Fridovich-Keil and Nithin Raghavan and Utkarsh Singhal and Ravi
            Ramamoorthi and Jonathan Barron and Ren Ng},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {7537--7547},
  year = {2020},
}

@inproceedings{rahimi2008random,
  title = {Random Features for Large-Scale Kernel Machines},
  author = {Ali Rahimi and Benjamin Recht},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {20},
  pages = {1177--1184},
  year = {2008},
}

@article{zheng2023study,
  title = {A Study on the Encoding Mechanism of Position Embeddings in Vision
           Transformers},
  author = {Ling Zheng and Shijie Wang and Yunfeng Liu and Chi-Hung Lee},
  year = {2023},
  eprint = {2309.07413},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  url = {https://arxiv.org/abs/2309.07413},
}

@book{cover2006elements,
  title = {Elements of Information Theory},
  author = {Thomas M. Cover and Joy A. Thomas},
  edition = {2nd},
  publisher = {John Wiley \& Sons},
  year = {2006},
}

@inproceedings{pascanu2013difficulty,
  title = {On the Difficulty of Training Recurrent Neural Networks},
  author = {Razvan Pascanu and Tomas Mikolov and Yoshua Bengio},
  booktitle = {International Conference on Machine Learning},
  pages = {1310--1318},
  year = {2013},
}

@inproceedings{bello2021attention,
  title = {Attention Approximates Sparse Distributed Memory},
  author = {Irwan Bello and Barret Zoph and Vijay Vasudevan and Quoc V. Le},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {15301--15315},
  year = {2021},
}

@article{oord2018representation,
  title = {Representation Learning with Contrastive Predictive Coding},
  author = {Aaron van den Oord and Yazhe Li and Oriol Vinyals},
  year = {2018},
  eprint = {1807.03748},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url = {https://arxiv.org/abs/1807.03748},
}

@article{peyre2019computational,
  title = {Computational Optimal Transport},
  author = {Gabriel Peyr\'{e} and Marco Cuturi},
  journal = {Foundations and Trends in Machine Learning},
  volume = {11},
  number = {5-6},
  pages = {355--607},
  year = {2019},
}

@inproceedings{voita2019analyzing,
  title = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy
           Lifting, the Rest Can Be Pruned},
  author = {Elena Voita and David Talbot and Fedor Moiseev and Rico Sennrich and
            Ivan Titov},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for
               Computational Linguistics},
  pages = {5797--5808},
  year = {2019},
}

@inproceedings{katharopoulos2020transformers,
  title = {Transformers are RNNs: Fast Autoregressive Transformers with Linear
           Attention},
  author = {Angelos Katharopoulos and Apoorv Vyas and Nikolaos Pappas and Fran\c
            {c}ois Fleuret},
  booktitle = {International Conference on Machine Learning},
  pages = {5156--5165},
  year = {2020},
}

@inproceedings{zaheer2020big,
  title = {Big Bird: Transformers for Longer Sequences},
  author = {Manzil Zaheer and Guru Guruganesh and Kumar Avinava Dubey and Joshua
            Ainslie and Chris Alberti and Santiago Ontanon and Philip Pham and
            Anirudh Ravula and Qifan Wang and Li Yang and Amr Ahmed},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {17283--17297},
  year = {2020},
}

@inproceedings{dai2019transformer,
  title = {Transformer-XL: Attentive Language Models Beyond a Fixed-Length
           Context},
  author = {Zihang Dai and Zhilin Yang and Yiming Yang and Jaime Carbonell and
            Quoc Le and Ruslan Salakhutdinov},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for
               Computational Linguistics},
  pages = {2978--2988},
  year = {2019},
}

@article{davies2018loihi,
  title = {Loihi: A Neuromorphic Manycore Processor with On-Chip Learning},
  author = {Mike Davies and Narayan Srinivasa and Tsung-Han Lin and Gautham
            Chinya and Yongqiang Cao and Sri Harsha Choday and Georgios Dimou and
            Prasad Joshi and Nabil Imam and Shweta Jain and Yuyun Liao and
            Chit-Kwan Lin and Andrew Lines and Ruokun Liu and Deepak Mathaikutty
            and Steven McCoy and Arnab Paul and Jonathan Tse and Guruguhanathan
            Venkataramanan and Yi-Hsin Weng and Andreas Wild and Yoonseok Yang
            and Hong Wang},
  journal = {IEEE Micro},
  volume = {38},
  number = {1},
  pages = {82--99},
  year = {2018},
}

@inproceedings{jouppi2023tpu,
  title = {TPU v4: An Optically Reconfigurable Supercomputer for Machine
           Learning with Hardware Support for Embeddings},
  author = {Norm Jouppi and George Kurian and Sheng Li and Peter Ma and Rahul
            Nagarajan and Lifeng Nai and Nishant Patil and Suvinay Subramanian
            and Andy Swing and Brian Towles and Cliff Young and Xiang Zhou and
            Zongwei Zhou and David Patterson},
  booktitle = {Proceedings of the 50th Annual International Symposium on
               Computer Architecture},
  pages = {1--14},
  year = {2023},
}

@inproceedings{hron2020infinite,
  title = {Infinite Attention: NNGP and NTK for Deep Attention Networks},
  author = {Jiri Hron and Yasaman Bahri and Jascha Sohl-Dickstein and Roman
            Novak},
  booktitle = {International Conference on Machine Learning},
  pages = {4376--4386},
  year = {2020},
}

@inproceedings{edelman2022inductive,
  title = {Inductive Biases and Variable Creation in Self-Attention Mechanisms},
  author = {Benjamin Edelman and Surbhi Goel and Sham Kakade and Cyril Zhang},
  booktitle = {International Conference on Machine Learning},
  pages = {5793--5831},
  year = {2022},
}

@inproceedings{tsai2019transformer,
  title = {Transformer Dissection: An Unified Understanding for Transformer's
           Attention via the Lens of Kernel},
  author = {Yao-Hung Hubert Tsai and Shaojie Bai and Makoto Yamada and
            Louis-Philippe Morency and Ruslan Salakhutdinov},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in
               Natural Language Processing},
  pages = {4344--4353},
  year = {2019},
}

@article{shah2024flashattention3,
  title = {FlashAttention-3: Fast and Accurate Attention with Asynchrony and
           Low-precision},
  author = {Jay Shah and Tri Dao and Christopher R\'{e}},
  year = {2024},
  eprint = {2405.17142},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  url = {https://arxiv.org/abs/2405.17142},
}
