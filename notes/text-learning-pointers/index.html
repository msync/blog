<!doctype html>
<html class="no-js" lang="en-us">
<head>
    <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<title>Text Learning - Pointers | Sync&#39;ing from Memory</title>
<meta property="og:title" content="Text Learning - Pointers"/>

<meta property="og:description" content="Pointers for DL for text"/>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:site" content="@jaju"/>
<meta name="twitter:creator" content="@jaju"/>

<meta name="viewport" content="width=device-width, initial-scale=1.0"/>


<link rel="stylesheet" type="text/css" href="https://msync.org/css/bundle.css">
<link rel="stylesheet" type="text/css" href="https://msync.org/css/hljs/rainbow.css">

</head>
<body>
<header>
    <div class="content">
  <a class="title" href="https://msync.org/">Sync&#39;ing from Memory</a>
  <nav>
    
    <a class="link" href="https://msync.org/notes/">Notes</a>
    
    <a class="link" href="https://msync.org/posts/">Posts</a>
    
  </nav>
</div>

</header>
<div id="main-wrapper">
    <div class="grid-x">
        <div class="cell medium-offset-1 medium-10 small-offset-1 small-10">
            <div id="main">
                

<div id="toc" class="cell hide-for-small-only">
  <div><nav id="TableOfContents">
<ul>
<li><a href="#headline-1">Synopsis</a>
</li>
<li><a href="#headline-2">Problems</a>
</li>
<li><a href="#headline-3">Approaches</a>
<ul>
<li><a href="#headline-4">NLP</a>
<ul>
<li><a href="#headline-5">Parsing</a>
</li>
<li><a href="#headline-6">Named Entities - Recognition, Disambiguation, Linking</a>
</li>
<li><a href="#headline-7">References</a>
</li>
</ul>
</li>
<li><a href="#headline-8">Dictionary</a>
</li>
<li><a href="#headline-9">Statistical (Machine Learning)</a>
</li>
</ul>
</li>
<li><a href="#headline-10">Useful reads</a>
<ul>
<li><a href="#headline-11">General reads</a>
</li>
<li><a href="#headline-12">Compilations</a>
</li>
<li><a href="#headline-13">Word sense disambiguation</a>
</li>
</ul>
</li>
<li><a href="#headline-14">Some publicly available trained word2vec datasets</a>
<ul>
<li><a href="#headline-15">Processed datasets</a>
</li>
<li><a href="#headline-16">Text datasets</a>
</li>
</ul>
</li>
<li><a href="#headline-17">Other datasets to build upon</a>
</li>
</ul>
</nav></div>
</div>

<article class="notes" itemscope itemtype="http://schema.org/CreativeWork">

  <header class="header">
    <h1 itemprop="name" class="title">Text Learning - Pointers</h1>
    <div class="meta">
      <span class="author-name" itemprop="author">
        Ravindra R. Jaju
      </span>
      <time datetime="2017-09-16 10:20:58 &#43;0530 IST" itemprop="datePublished" class="pubdate">
        <span class="weekday">Sat</span>,
        <span class="day">16</span>
        <span class="month">Sep</span>,
        <span class="year">2017</span>
      </time>

      
      <time datetime="2017-10-09 12:42:15 &#43;0530 IST" itemprop="datePublished" class="pubdate">
        Last updated:
        <span class="weekday">Mon</span>,
        <span class="day">9</span>
        <span class="month">Oct</span>,
        <span class="year">2017</span>
      </time>
      
    </div>
  </header>

  <summary>
    Pointers for DL for text
  </summary>

  <main>
    
<div id="outline-container-headline-1" class="outline-2">
<h2 id="headline-1">
Synopsis
</h2>
<div id="outline-text-headline-1" class="outline-text-2">
<p>Text learning combines various disciplines. Of course, that&#39;s true for all domains in which machine learning will be applied. But text is special
because that defines humans in very special and unique ways, and with speech, is our primary form of knowledge encoding, storing, and communication.</p>
<p>
Non-exhaustively, and probably haphazardly, I have the following in my mind for this document.</p>
<ul>
<li>
<p>Good corpus. Bad corpus.</p>
</li>
<li>
<p>NLP. Statistics. Dictionaries. Knowledge-bases.</p>
</li>
<li>
<p><em>SpaCy</em>. <em>CoreNLP</em>. <em>GATE</em>.</p>
</li>
<li>
<p><em>Word2Vec</em>. <em>GloVe</em>. <em>Sense2Vec</em>.</p>
</li>
<li>
<p>The <em>whats</em> and the <em>whys</em>, and pointers to the <em>hows</em>.</p>
</li>
</ul>
<p>Primarily my notes for reference.</p>
</div>
</div>
<div id="outline-container-headline-2" class="outline-2">
<h2 id="headline-2">
Problems
</h2>
<div id="outline-text-headline-2" class="outline-text-2">
<p>The most obvious ones are the ones many researchers and tools have taken care of very well. In other words, they are not much
of a problem.</p>
<p>
User generated content (<strong>UGC</strong>) on various social media sites present most of the challenge. No editors to supervise quality of
the text (facts - or <em>fact free</em> - is an orthogonal concern.) Grammar and spelling errors. Incomplete sentences. #HashtagsMadeUpOfWordsYouCantFindBoundariesOfToTagBetter.</p>
<p>
There&#39;s this inherent, <em>embedded</em> challenge. And then there&#39;s the extraneous challenge - that neither do we have much standard
corpus of <strong>UGC</strong>, nor do we find any that are labelled. Any attempt to create a standard corpus will face the risk of being
obsolete by the time it becomes a standard. Social-media-text evolves much too rapidly, and new words are created and discarded
without any regard to, well, anything.</p>
<p>
So, naïve statistics is bound to fail for reasons of finding too little of everything, to generalize from. <em>Noise</em>! And so is standard NLP.
Then there are styles influenced by the platforms that host content. <code>@NameTagging</code> and <code>#hashtags</code>, for example. And we don&#39;t know
how the recent migration (for some, for now) to the 280-character limit by Twitter will affect styles and content. It&#39;s generally
hard to predict about anything, and especially the future.</p>
</div>
</div>
<div id="outline-container-headline-3" class="outline-2">
<h2 id="headline-3">
Approaches
</h2>
<div id="outline-text-headline-3" class="outline-text-2">
<div id="outline-container-headline-4" class="outline-3">
<h3 id="headline-4">
NLP
</h3>
<div id="outline-text-headline-4" class="outline-text-3">
<p>
<a href="https://spacy.io/">SpaCy</a> is one tool that gets you started very quickly, and is fast. The accuracy and performance claims make it a very compelling choice.
And my personal experience around the responsiveness while reporting a <a href="https://github.com/explosion/spaCy/issues/1336">bug</a> on the the 2-alpha branch left me impressed.
SpaCy is Python based. Which is a plus, given the ecosystem.</p>
<div id="outline-container-headline-5" class="outline-4">
<h4 id="headline-5">
Parsing
</h4>
</div>
<div id="outline-container-headline-6" class="outline-4">
<h4 id="headline-6">
Named Entities - Recognition, Disambiguation, Linking
</h4>
<div id="outline-text-headline-6" class="outline-text-4">
<p>Some key terms</p>
<ul>
<li>
<p>Named Entity</p>
</li>
<li>
<p>Knowledge Base (<strong>KB</strong>)</p>
</li>
<li>
<p>Mention</p>
</li>
<li>
<p>Named Entity Recognition (<strong>NER</strong>)</p>
</li>
</ul>
</div>
</div>
<div id="outline-container-headline-7" class="outline-4">
<h4 id="headline-7">
References
</h4>
<div id="outline-text-headline-7" class="outline-text-4">
<ul>
<li>
<p><a href="https://spacy.io/">SpaCy</a></p>
</li>
<li>
<p><a href="http://scidok.sulb.uni-saarland.de/volltexte/2016/6370/pdf/mamir_dissertation_with_reviewers.pdf">U-AIDA: a Customizable System for Named Entity Recognition, Classification, and Disambiguation {AIDA:Dissertaion}</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-8" class="outline-3">
<h3 id="headline-8">
Dictionary
</h3>
<div id="outline-text-headline-8" class="outline-text-3">
<p>Nobody got fired for relying on <a href="https://wordnet.princeton.edu/">WordNet</a>. English-focused, but you can extend using their framework. Of course, the effort is all yours to make.</p>
</div>
</div>
<div id="outline-container-headline-9" class="outline-3">
<h3 id="headline-9">
Statistical (Machine Learning)
</h3>
<div id="outline-text-headline-9" class="outline-text-3">
<p>Given any dataset, statistical analyses are your best bet given no other help to gain insights.</p>
<p>
Combined with language-domain expertise (NLP, dictionaries, ontologies etc.), statistics give you higher accuracy at speed and scale.</p>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-10" class="outline-2">
<h2 id="headline-10">
Useful reads
</h2>
<div id="outline-text-headline-10" class="outline-text-2">
<div id="outline-container-headline-11" class="outline-3">
<h3 id="headline-11">
General reads
</h3>
<div id="outline-text-headline-11" class="outline-text-3">
<ul>
<li>
<p><a href="https://nlp.stanford.edu/pubs/glove.pdf">The GloVe paper</a></p>
</li>
<li>
<p><a href="https://code.google.com/archive/p/word2vec/">Google word2vec</a> archive site</p>
</li>
<li>
<p><a href="https://rare-technologies.com/making-sense-of-word2vec/">Making sense of word2vec</a> - a blog post discussing word2vec vis-a-vis GloVe</p>
</li>
</ul>
</div>
</div>
<div id="outline-container-headline-12" class="outline-3">
<h3 id="headline-12">
Compilations
</h3>
<div id="outline-text-headline-12" class="outline-text-3">
<ul>
<li>
<p><a href="https://medium.com/towards-data-science/how-to-get-started-in-nlp-6a62aa4eaeff">How to get started in NLP</a></p>
</li>
</ul>
</div>
</div>
<div id="outline-container-headline-13" class="outline-3">
<h3 id="headline-13">
Word sense disambiguation
</h3>
<div id="outline-text-headline-13" class="outline-text-3">
<ul>
<li>
<p><a href="https://arxiv.org/pdf/1511.06388.pdf">Sense2vec - A fast and accurate method… neural word embeddings</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-14" class="outline-2">
<h2 id="headline-14">
Some publicly available trained word2vec datasets
</h2>
<div id="outline-text-headline-14" class="outline-text-2">
<ul>
<li>
<p><a href="https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-model">https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-model</a> appears to be a good list that I could quickly reach via a G-search.</p>
</li>
<li>
<p><a href="https://code.google.com/archive/p/word2vec/">Google&#39;s (archived?) word2vec code site</a></p>
</li>
<li>
<p><a href="https://github.com/idio/wiki2vec">Utilities + Processed models for some Wikipedia data</a></p>
</li>
</ul>
<p>Reproducing a few of the ones here just in case.</p>
<div id="outline-container-headline-15" class="outline-3">
<h3 id="headline-15">
Processed datasets
</h3>
<div id="outline-text-headline-15" class="outline-text-3">
<table>
<thead>
<tr>
<th>Dataset name</th>
<th class="align-right">Dimensions</th>
<th>Corpus size</th>
<th>Vocabulary size</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/">Google News</a></td>
<td class="align-right">300</td>
<td>100B</td>
<td>3M</td>
<td>Google</td>
</tr>
<tr>
<td><a href="https://docs.google.com/file/d/0B7XkCwpI5KDYaDBDQm1tZGNDRHc/edit?usp=sharing">Freebase IDs</a></td>
<td class="align-right">1000</td>
<td>100B (Google News)</td>
<td>1.4M</td>
<td>Google</td>
</tr>
<tr>
<td><a href="https://docs.google.com/file/d/0B7XkCwpI5KDYeFdmcVltWkhtbmM/edit?usp=sharing">Freebase Names</a></td>
<td class="align-right">1000</td>
<td>100B (Google News)</td>
<td>1.4M</td>
<td>Google</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-headline-16" class="outline-3">
<h3 id="headline-16">
Text datasets
</h3>
<div id="outline-text-headline-16" class="outline-text-3">
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Corpus size</th>
<th>Additional notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://mattmahoney.net/dc/enwik9.zip">First billion Wikipedia words</a></td>
<td>1B words</td>
<td>Use the pre-processing perl script from the bottom of <a href="http://mattmahoney.net/dc/textdata.html">Matt Mahoney&#39;s page</a></td>
</tr>
<tr>
<td><a href="http://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2">Latest Wikipedia dump</a></td>
<td>&gt; 3B words</td>
<td>Use the same script as above</td>
</tr>
<tr>
<td><a href="http://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz">Dataset from &#34;One Billion Word Language Modeling Benchmark&#34;</a></td>
<td>1B words</td>
<td>Already pre-processed</td>
</tr>
<tr>
<td><a href="http://ebiquity.umbc.edu/redirect/to/resource/id/351/UMBC-webbase-corpus">UMBC webbase corpus</a></td>
<td>~3B words</td>
<td>Needs to be processed. Mainly tokenization</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-17" class="outline-2">
<h2 id="headline-17">
Other datasets to build upon
</h2>
<div id="outline-text-headline-17" class="outline-text-2">
<ul>
<li>
<p><a href="https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/">&#34;YAGO: A High-Quality Knowledge Base&#34;</a> - It is a <span style="text-decoration: underline;">semantic knowledgebase</span> derived from <a href="https://en.wikipedia.org/">Wikipedia</a>, <a href="http://wordnet.princeton.edu/">WordNet</a> and <a href="http://www.geonames.org/">GeoNames</a>. Contains 10+ million entities, and 100+ million facts about them.</p>
</li>
</ul>
</div>
</div>

  </main>

</article>

            </div>
        </div>
    </div>
</div>
<footer>
    <div class="hide-for-small-only float-left">
  <span>&copy; <span class="author-name">Ravindra R. Jaju</span> &mdash; 2015-2021</span>
</div>

<div class="social-media-list float-right">

  <span class="social-media-item">
    <a href="https://github.com/jaju">
      <span class="svg-social-icon icon--github">
        <svg viewBox="0 0 16 16">
          <path fill="#828282"
                d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
        </svg>
      </span>
      <span class="username">jaju</span>
    </a>
  </span>
  <span class="social-media-item">
    <a href="https://twitter.com/jaju">
      <span class="svg-social-icon icon--twitter">
        <svg viewBox="0 0 16 16">
          <path fill="#828282"
                d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809 c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
        </svg>
      </span>
      <span class="username">jaju</span>
    </a>
  </span>

</div>

</footer>
<script src="/js/bundle.js"></script>
<script>hljs.highlightAll();</script>
<script>
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-1397428-5', 'auto');
    ga('send', 'pageview');
</script>
</body>
</html>