<!doctype html>
<html class="no-js" lang="en-us">

<head>
    <meta charset="utf-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<title>Text Learning - Pointers | Sync&#39;ing from Memory</title>
<meta property="og:title" content="Text Learning - Pointers"/>

<meta property="og:description" content="Pointers for DL for text"/>

<meta name="twitter:card" content="summary"/>
<meta name="twitter:site" content="@jaju"/>
<meta name="twitter:creator" content="@jaju"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>


<link rel="stylesheet" type="text/css" href="https://msync.org/css/bundle.css">
<link rel="stylesheet" type="text/css" href="https://msync.org/css/hljs/rainbow.css">
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

<body>

<div id="body">
    <header id="site-header">
        <div class="content">
  <a href="https://msync.org/">Sync&#39;ing from Memory</a>
  <nav>
    
    <a href="https://msync.org/notes/">Notes</a>
    
    <a href="https://msync.org/posts/">Posts</a>
    
  </nav>
</div>
    </header>

    <div id="main-wrapper">
        
<div class="content notes">

    <div class="toc">
        <nav id="TableOfContents">
  <ol>
    <li>
      <ol>
        <li><a href="#synopsis">Synopsis</a></li>
        <li><a href="#problems">Problems</a></li>
        <li><a href="#approaches">Approaches</a>
          <ol>
            <li><a href="#nlp">NLP</a></li>
            <li><a href="#dictionary">Dictionary</a></li>
            <li><a href="#statistical--machine-learning">Statistical (Machine Learning)</a></li>
          </ol>
        </li>
        <li><a href="#useful-reads">Useful reads</a>
          <ol>
            <li><a href="#general-reads">General reads</a></li>
            <li><a href="#compilations">Compilations</a></li>
            <li><a href="#word-sense-disambiguation">Word sense disambiguation</a></li>
          </ol>
        </li>
        <li><a href="#some-publicly-available-trained-word2vec-datasets">Some publicly available trained word2vec datasets</a>
          <ol>
            <li><a href="#processed-datasets">Processed datasets</a></li>
            <li><a href="#text-datasets">Text datasets</a></li>
          </ol>
        </li>
        <li><a href="#other-datasets-to-build-upon">Other datasets to build upon</a></li>
      </ol>
    </li>
  </ol>
</nav>
    </div>

    <article itemscope itemtype="http://schema.org/CreativeWork">

        <header>
            <h1 itemprop="title">Text Learning - Pointers</h1>
            <summary>
                Pointers for DL for text
            </summary>
            <div class="meta">
                
                <span class="author" itemprop="author">
                    
                          &#34;Ravindra R. Jaju&#34;
  
                    
                </span>
                
                <div class="time">
                <time datetime="2017-09-16 10:20:58 &#43;0530 IST" itemprop="datePublished" class="pubdate">
                    <span class="weekday">Sat</span>,
                    <span class="day">16</span>
                    <span class="month">Sep</span>,
                    <span class="year">2017</span>
                </time>

                
                <time datetime="2024-03-09 08:53:18 &#43;0530 IST" itemprop="dateModified" class="pubdate">
                    Updated:
                    <span class="weekday">Sat</span>,
                    <span class="day">9</span>
                    <span class="month">Mar</span>,
                    <span class="year">2024</span>
                </time>
                
                </div>
            </div>
        </header>

        <main>
            <h2 id="synopsis">Synopsis</h2>
<p>Text learning combines various disciplines. Of course, that&rsquo;s true for all domains in which machine learning will be applied. But text is special because that defines humans in very special and unique ways, and with speech, is our primary form of knowledge encoding, storing, and communication.</p>
<p>Non-exhaustively, and probably haphazardly, I have the following in my mind for this document.</p>
<ul>
<li>Good corpus. Bad corpus.</li>
<li>NLP. Statistics. Dictionaries. Knowledge-bases.</li>
<li><em>SpaCy</em>. <em>CoreNLP</em>. <em>GATE</em>.</li>
<li><em>Word2Vec</em>. <em>GloVe</em>. <em>Sense2Vec</em>.</li>
<li>The <em>whats</em> and the <em>whys</em>, and pointers to the <em>hows</em>.</li>
</ul>
<p>Primarily my notes for reference.</p>
<h2 id="problems">Problems</h2>
<p>The most obvious ones are the ones many researchers and tools have taken care of very well. In other words, they are not much
of a problem.</p>
<p>User generated content (<strong>UGC</strong>) on various social media sites present most of the challenge. No editors to supervise quality of
the text (facts - or <em>fact free</em> - is an orthogonal concern.) Grammar and spelling errors. Incomplete sentences. #HashtagsMadeUpOfWordsYouCantFindBoundariesOfToTagBetter.</p>
<p>There&rsquo;s this inherent, <em>embedded</em> challenge. And then there&rsquo;s the extraneous challenge - that neither do we have much standard
corpus of <strong>UGC</strong>, nor do we find any that are labelled. Any attempt to create a standard corpus will face the risk of being
obsolete by the time it becomes a standard. Social-media-text evolves much too rapidly, and new words are created and discarded
without any regard to, well, anything.</p>
<p>So, na√Øve statistics is bound to fail for reasons of finding too little of everything, to generalize from. <em>Noise</em>! And so is standard NLP.
Then there are styles influenced by the platforms that host content. <code>@NameTagging</code> and <code>#hashtags</code>, for example. And we don&rsquo;t know
how the recent migration (for some, for now) to the 280-character limit by Twitter will affect styles and content. It&rsquo;s generally
hard to predict about anything, and especially the future.</p>
<h2 id="approaches">Approaches</h2>
<h3 id="nlp">NLP</h3>
<p><a href="https://spacy.io/">SpaCy</a> is one tool that gets you started very quickly, and is fast. The accuracy and performance claims make it a very compelling choice.
And my personal experience around the responsiveness while reporting a <a href="https://github.com/explosion/spaCy/issues/1336">bug</a> on the the 2-alpha branch left me impressed.
SpaCy is Python based. Which is a plus, given the ecosystem.</p>
<h4 id="parsing">Parsing</h4>
<h4 id="named-entities-recognition-disambiguation-linking">Named Entities - Recognition, Disambiguation, Linking</h4>
<p>Some key terms</p>
<ul>
<li>Named Entity</li>
<li>Knowledge Base (<strong>KB</strong>)</li>
<li>Mention</li>
<li>Named Entity Recognition (<strong>NER</strong>)</li>
</ul>
<h4 id="references">References</h4>
<ul>
<li><a href="https://spacy.io/">SpaCy</a></li>
<li><a href="http://scidok.sulb.uni-saarland.de/volltexte/2016/6370/pdf/mamir_dissertation_with_reviewers.pdf">U-AIDA: a Customizable System for Named Entity Recognition, Classification, and Disambiguation {AIDA:Dissertaion}</a></li>
</ul>
<h3 id="dictionary">Dictionary</h3>
<p>Nobody got fired for relying on <a href="https://wordnet.princeton.edu/">WordNet</a>. English-focused, but you can extend using their framework. Of course, the effort is all yours to make.</p>
<h3 id="statistical--machine-learning">Statistical (Machine Learning)</h3>
<p>Given any dataset, statistical analyses are your best bet given no other help to gain insights.</p>
<p>Combined with language-domain expertise (NLP, dictionaries, ontologies etc.), statistics give you higher accuracy at speed and scale.</p>
<h2 id="useful-reads">Useful reads</h2>
<h3 id="general-reads">General reads</h3>
<ul>
<li><a href="https://nlp.stanford.edu/pubs/glove.pdf">The GloVe paper</a></li>
<li><a href="https://code.google.com/archive/p/word2vec/">Google word2vec</a> archive site</li>
<li><a href="https://rare-technologies.com/making-sense-of-word2vec/">Making sense of word2vec</a> - a blog post discussing word2vec vis-a-vis GloVe</li>
</ul>
<h3 id="compilations">Compilations</h3>
<ul>
<li><a href="https://medium.com/towards-data-science/how-to-get-started-in-nlp-6a62aa4eaeff">How to get started in NLP</a></li>
</ul>
<h3 id="word-sense-disambiguation">Word sense disambiguation</h3>
<ul>
<li><a href="https://arxiv.org/pdf/1511.06388.pdf">Sense2vec - A fast and accurate method&hellip; neural word embeddings</a></li>
</ul>
<h2 id="some-publicly-available-trained-word2vec-datasets">Some publicly available trained word2vec datasets</h2>
<ul>
<li><a href="https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-model">https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-model</a> appears to be a good list that I could quickly reach via a G-search.</li>
<li><a href="https://code.google.com/archive/p/word2vec/">Google&rsquo;s (archived?) word2vec code site</a></li>
<li><a href="https://github.com/idio/wiki2vec">Utilities + Processed models for some Wikipedia data</a></li>
</ul>
<p>Reproducing a few of the ones here just in case.</p>
<h3 id="processed-datasets">Processed datasets</h3>
<table>
<thead>
<tr>
<th>Dataset name</th>
<th>Dimensions</th>
<th>Corpus size</th>
<th>Vocabulary size</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/">Google News</a></td>
<td>300</td>
<td>100B</td>
<td>3M</td>
<td>Google</td>
</tr>
<tr>
<td><a href="https://docs.google.com/file/d/0B7XkCwpI5KDYaDBDQm1tZGNDRHc/edit?usp=sharing">Freebase IDs</a></td>
<td>1000</td>
<td>100B (Google News)</td>
<td>1.4M</td>
<td>Google</td>
</tr>
<tr>
<td><a href="https://docs.google.com/file/d/0B7XkCwpI5KDYeFdmcVltWkhtbmM/edit?usp=sharing">Freebase Names</a></td>
<td>1000</td>
<td>100B (Google News)</td>
<td>1.4M</td>
<td>Google</td>
</tr>
</tbody>
</table>
<h3 id="text-datasets">Text datasets</h3>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Corpus size</th>
<th>Additional notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://mattmahoney.net/dc/enwik9.zip">First billion Wikipedia words</a></td>
<td>1B words</td>
<td>Use the pre-processing perl script from the bottom of <a href="http://mattmahoney.net/dc/textdata.html">Matt Mahoney&rsquo;s page</a></td>
</tr>
<tr>
<td><a href="http://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2">Latest Wikipedia dump</a></td>
<td>&gt; 3B words</td>
<td>Use the same script as above</td>
</tr>
<tr>
<td><a href="http://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz">Dataset from &ldquo;One Billion Word Language Modeling Benchmark&rdquo;</a></td>
<td>1B words</td>
<td>Already pre-processed</td>
</tr>
<tr>
<td><a href="http://ebiquity.umbc.edu/redirect/to/resource/id/351/UMBC-webbase-corpus">UMBC webbase corpus</a></td>
<td>~3B words</td>
<td>Needs to be processed. Mainly tokenization</td>
</tr>
</tbody>
</table>
<h2 id="other-datasets-to-build-upon">Other datasets to build upon</h2>
<ul>
<li><a href="https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/">&ldquo;YAGO: A High-Quality Knowledge Base&rdquo;</a> - It is a <span class="underline">semantic knowledgebase</span> derived from <a href="https://en.wikipedia.org/">Wikipedia</a>, <a href="http://wordnet.princeton.edu/">WordNet</a> and <a href="http://www.geonames.org/">GeoNames</a>. Contains 10+ million entities, and 100+ million facts about them.</li>
</ul>

        </main>

    </article>

</div>

    </div>

    <footer id="site-footer">
        <div class="hide-for-small-only float-left author">
  <span>&copy; <span class="author-name">Ravindra R. Jaju</span> &mdash; 2015-2024</span>
</div>

<div class="social-media-list float-right">

  <span class="social-media-item">
    <a href="https://github.com/jaju">
      <span class="svg-social-icon icon--github">
        <svg viewBox="0 0 16 16">
          <path fill="#828282"
                d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
        </svg>
      </span>
      <span class="username">jaju</span>
    </a>
  </span>
  <span class="social-media-item">
    <a href="https://twitter.com/jaju">
      <span class="svg-social-icon icon--twitter">
        <svg viewBox="0 0 16 16">
          <path fill="#828282"
                d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809 c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
        </svg>
      </span>
      <span class="username">jaju</span>
    </a>
  </span>

</div>

    </footer>
</div>

<script src="/js/bundle.js"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1397428-5"></script>
<script>
    window.hljs.highlightAll();

    window.dataLayer = window.dataLayer || [];
    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'UA-1397428-5');
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-1397428-5', 'auto');
    ga('send', 'pageview');
</script>
</body>
</html>
