<!DOCTYPE html>
<html lang="en-us"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">Whisper and STT on Apple Silicon | M&#39;Sync</title>
<meta property="og:title" content="Whisper and STT on Apple Silicon | M&#39;Sync" />
<meta name="twitter:title" content="Whisper and STT on Apple Silicon | M&#39;Sync" />
<meta itemprop="name" content="Whisper and STT on Apple Silicon | M&#39;Sync" />
<meta name="application-name" content="Whisper and STT on Apple Silicon | M&#39;Sync" />
<meta property="og:site_name" content="M&#39;Sync" />

<meta name="description" content="Notes, experiments, and experience reports on systems, machine learning, and engineering craft.">
<meta itemprop="description" content="Notes, experiments, and experience reports on systems, machine learning, and engineering craft." />
<meta property="og:description" content="Notes, experiments, and experience reports on systems, machine learning, and engineering craft." />
<meta name="twitter:description" content="Notes, experiments, and experience reports on systems, machine learning, and engineering craft." />

<meta property="og:locale" content="en-us" />
<meta name="language" content="en-us" />

  <link rel="alternate" hreflang="en" href="http://localhost:1313/blog/2025/2025-09-24-whisper-on-apple-silicon/" title="" />






<meta name="generator" content="Hugo 0.155.3">

    
    <meta property="og:url" content="http://localhost:1313/blog/2025/2025-09-24-whisper-on-apple-silicon/">
  <meta property="og:site_name" content="M&#39;Sync">
  <meta property="og:title" content="Whisper and STT on Apple Silicon">
  <meta property="og:description" content="Whisper Notes from My Mac (September 2025) I spent the past few days gluing together a speech‑to‑text workflow on my Apple Silicon MacBook (macOS 26.0, Python 3.12). Most of what follows is a log of what actually happened: which warnings popped up, how I worked around them, and why I eventually leaned on whisper.cpp. I’m keeping this grounded so I (or anyone else) can repeat the steps later without guesswork.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-09-24T09:00:00+05:30">
    <meta property="article:modified_time" content="2025-09-24T09:00:00+05:30">
    <meta property="article:tag" content="Experience">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Whisper and STT on Apple Silicon">
  <meta name="twitter:description" content="Whisper Notes from My Mac (September 2025) I spent the past few days gluing together a speech‑to‑text workflow on my Apple Silicon MacBook (macOS 26.0, Python 3.12). Most of what follows is a log of what actually happened: which warnings popped up, how I worked around them, and why I eventually leaned on whisper.cpp. I’m keeping this grounded so I (or anyone else) can repeat the steps later without guesswork.">


    

    <link rel="canonical" href="http://localhost:1313/blog/2025/2025-09-24-whisper-on-apple-silicon/">
    <link href="/style.min.c2b918d0b645b6732a537299abbcdb9450c4426034e60ae83fa3b194686e2200.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="http://localhost:1313/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
      


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">


<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>


<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: false });
  document.addEventListener('DOMContentLoaded', () => {
    document.querySelectorAll('code.language-mermaid').forEach((el) => {
      const pre = el.parentElement;
      const div = document.createElement('div');
      div.classList.add('mermaid');
      div.textContent = el.textContent;
      pre.parentElement.replaceChild(div, pre);
    });
    mermaid.run();
  });
</script>
    
</head>
<body data-theme = "light" class="notransition">

<script src="/js/theme.js"></script>

<div class="navbar" role="navigation">
  <nav class="menu" aria-label="Primary navigation">
    <a href="http://localhost:1313/" class="logo" aria-label="M&#39;Sync">
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title>Home</title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
      <span class="logo-text">M&#39;Sync</span>
    </a>
    <input type="checkbox" id="menu-trigger" class="menu-trigger" aria-hidden="true" />
    <label for="menu-trigger" class="menu-toggle" aria-controls="site-menu" aria-label="Toggle navigation">
      <span class="menu-icon">
        <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
      </span>
    </label>

    <div class="trigger" id="site-menu">
      <ul class="trigger-container">
        
        
        <li>
          <a class="menu-link " href="/">
            Home
          </a>
          
        </li>
        
        <li>
          <a class="menu-link " href="/notes/">
            Notes
          </a>
          
        </li>
        
        <li>
          <a class="menu-link " href="/blog/">
            Blog
          </a>
          
        </li>
        
        
      </ul>
      <a id="mode" href="#" aria-label="Toggle color scheme">
        <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>Light mode</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
        <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>Dark mode</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
      </a>
    </div>
  </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">Whisper and STT on Apple Silicon</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2025-09-24T09:00:00&#43;05:30" itemprop="datePublished"> Sep 24, 2025 </time>
                </div>
                
            </header>
            
            <div class="page-content">
                <h1 id="whisper-notes-from-my-mac-september2025">Whisper Notes from My Mac (September 2025)</h1>
<p>I spent the past few days gluing together a speech‑to‑text workflow on my Apple Silicon MacBook (macOS 26.0, Python 3.12). Most of what follows is a log of what actually happened: which warnings popped up, how I worked around them, and why I eventually leaned on whisper.cpp. I’m keeping this grounded so I (or anyone else) can repeat the steps later without guesswork.</p>
<hr>
<h2 id="environment-snapshot">Environment Snapshot</h2>
<p>All version numbers below come straight from the venv and host (<code>sw_vers</code>, <code>python -V</code>, <code>importlib.metadata.version</code>).</p>
<table>
  <thead>
      <tr>
          <th>Component</th>
          <th>Version / detail</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>macOS</td>
          <td>26.0</td>
      </tr>
      <tr>
          <td>Python</td>
          <td>3.12.5</td>
      </tr>
      <tr>
          <td><code>transformers</code></td>
          <td>4.46.1</td>
      </tr>
      <tr>
          <td><code>torch</code></td>
          <td>2.8.0</td>
      </tr>
      <tr>
          <td><code>soundfile</code></td>
          <td>0.13.1</td>
      </tr>
      <tr>
          <td>HF checkpoint</td>
          <td><code>openai/whisper-large-v3-turbo</code></td>
      </tr>
      <tr>
          <td>whisper.cpp</td>
          <td>CLI at <code>$HOME/bin/whisper-cli</code>, model <code>ggml-large-v3-turbo.bin</code></td>
      </tr>
  </tbody>
</table>
<p>All test clips were mono WAV (16 kHz).</p>
<hr>
<h2 id="1-what-huggingface-whisper-looked-like-on-this-machine">1. What Hugging Face Whisper Looked Like on This Machine</h2>
<h3 id="11-device-and-dtype-quirks">1.1 Device and dtype quirks</h3>
<p>If I let Transformers pick the Metal backend (<code>device=&quot;mps&quot;</code>), <code>generate()</code> occasionally crashed with <code>RuntimeError: Input type (float) and bias type (c10::Half) should be the same</code>. The model had moved to float16 on GPU while the feature extractor ran on CPU in float32. To keep things reliable, I now move the model back to CPU before creating the pipeline (and the pipeline itself runs with <code>device=-1</code>). CUDA users don’t usually see this; on Apple Silicon the CPU path was the safe bet.</p>
<h3 id="12-greedy-decoding-vs-beam-search">1.2 Greedy decoding vs. beam search</h3>
<p>Short clips were the first surprise: greedy decoding auto-detected Urdu and produced <code>شکریہ</code>. That’s technically correct, but I wanted Devanagari, so I forced the language prompt and enabled beam search:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">forced</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">get_decoder_prompt_ids</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">language</span><span class="o">=</span><span class="s2">&#34;hi&#34;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&#34;transcribe&#34;</span><span class="p">,</span> <span class="n">no_timestamps</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_features</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">forced_decoder_ids</span><span class="o">=</span><span class="n">forced</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">attention_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">input_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>The pipeline also honours <code>generate_kwargs</code>, so I now pass <code>language</code> and <code>num_beams</code> explicitly every time.</p>
<h3 id="13-long-audio-chunking">1.3 Long audio chunking</h3>
<p>My first attempt at chunking was a naïve slice (<code>range(0, len, chunk_len)</code>), and later segments went missing because I wasn’t overlapping windows or reusing prompts. Switching to the built-in pipeline fixed that for me:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">asr</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;automatic-speech-recognition&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span><span class="o">=</span><span class="s2">&#34;openai/whisper-large-v3-turbo&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">device</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">asr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span><span class="s2">&#34;array&#34;</span><span class="p">:</span> <span class="n">audio_np</span><span class="p">,</span> <span class="s2">&#34;sampling_rate&#34;</span><span class="p">:</span> <span class="n">sr</span><span class="p">},</span>
</span></span><span class="line"><span class="cl">    <span class="n">chunk_length_s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">stride_length_s</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">generate_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;language&#34;</span><span class="p">:</span> <span class="s2">&#34;hi&#34;</span><span class="p">,</span> <span class="s2">&#34;task&#34;</span><span class="p">:</span> <span class="s2">&#34;transcribe&#34;</span><span class="p">,</span> <span class="s2">&#34;num_beams&#34;</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>Letting the pipeline handle overlap and context reuse was much less error-prone than reinventing it. In my session helper I also move the cached model back to CPU before instantiating the pipeline so I don’t trip over Metal-related dtype issues.</p>
<h3 id="14-warnings-worth-heeding">1.4 Warnings worth heeding</h3>
<ol>
<li><a href="https://huggingface.co/docs/transformers/main/en/internal/generation_utils#transformers.GenerationMixin.generate"><code>return_dict_in_generate</code></a> vs <code>output_scores</code>: if you want per-token scores, you must set both. Otherwise the scores are silently dropped.</li>
<li>Language auto-detect: after <a href="https://github.com/huggingface/transformers/pull/28687">PR #28687</a> (Mar 2024), multilingual Whisper defaults to detection + transcription. I now always set <code>language=&quot;hi&quot;</code> (or whatever I need) to avoid unexpected translations.</li>
<li><code>past_key_values</code>: Transformers 4.47 moves to <code>EncoderDecoderCache</code>. If the legacy tuple is still needed, <code>return_legacy_cache=True</code> keeps things working for now (see the <a href="https://github.com/huggingface/transformers/releases/tag/v4.47.0">4.47 release notes</a>).</li>
<li>Attention mask: pad token equals EOS, so the model can’t infer the mask. Passing an explicit <code>attention_mask</code> stopped the warning and gave me more predictable behaviour (documented in the <a href="https://huggingface.co/docs/transformers/main/en/model_doc/whisper#usage-notes">Whisper generation guide</a>).</li>
</ol>
<h3 id="15-throughput-snapshot">1.5 Throughput snapshot</h3>
<p>Transcribing a ~90 s clip on CPU, beam search enabled, took roughly 45 s and produced a readable transcript with a few garbled phrases. Good enough for experiments, not ideal for “fast feedback”.</p>
<hr>
<h2 id="2-what-changed-when-i-tried-whispercpp">2. What Changed When I Tried whisper.cpp</h2>
<h3 id="21-cli-run">2.1 CLI run</h3>
<p>I pointed the whisper.cpp CLI at the same ~90 s clip using:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">whisper-cli <span class="se">\
</span></span></span><span class="line"><span class="cl">  -m /Users/jaju/github-others/ggerganov/whisper.cpp/models/ggml-large-v3-turbo.bin <span class="se">\
</span></span></span><span class="line"><span class="cl">  -l hi <span class="se">\
</span></span></span><span class="line"><span class="cl">  --output-json -of outputs/sample_cpp <span class="se">\
</span></span></span><span class="line"><span class="cl">  audata/audio/audio_message.wav
</span></span></code></pre></div><p>The run finished in about 29 s on the same Mac, the transcript looked cleaner, and I didn’t see any repeated segments. For larger batches, that speed difference is hard to ignore.</p>
<h3 id="22-http-server">2.2 HTTP server</h3>
<p>Starting the whisper.cpp server (<code>whisper-server</code>) gave me a simple REST endpoint:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">curl 127.0.0.1:8181/inference <span class="se">\
</span></span></span><span class="line"><span class="cl">  -F <span class="nv">file</span><span class="o">=</span>@audata/audio/audio_message.wav <span class="se">\
</span></span></span><span class="line"><span class="cl">  -F <span class="nv">language</span><span class="o">=</span><span class="s2">&#34;hi&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl">  -F <span class="nv">temperature</span><span class="o">=</span><span class="s2">&#34;0.0&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl">  -F <span class="nv">temperature_inc</span><span class="o">=</span><span class="s2">&#34;0.0&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl">  -F <span class="nv">response_format</span><span class="o">=</span><span class="s2">&#34;verbose_json&#34;</span>
</span></span></code></pre></div><p>The response includes segment start/end offsets and text. I normalised the whitespace when parsing so the session log just sees plain paragraphs. Latency was around 10–12 s for the same clip, already faster than the HF pipeline.</p>
<h3 id="23-what-i-have-not-finished-yet">2.3 What I have <em>not</em> finished yet</h3>
<p>whisper.cpp also supports grammar-based decoding (GBNF). I haven’t tried that in this project, so it’s on the “explore later” list rather than a recommendation.</p>
<hr>
<h2 id="3-picking-a-backend-day-to-day">3. Picking a Backend Day to Day</h2>
<table>
  <thead>
      <tr>
          <th>Scenario</th>
          <th>HF Transformers</th>
          <th>whisper.cpp</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Need LoRA / fine-tuning</td>
          <td>✅</td>
          <td>⚠️ (inference only)</td>
      </tr>
      <tr>
          <td>Python ecosystem (datasets, analytics)</td>
          <td>✅</td>
          <td>Use CLI / bindings</td>
      </tr>
      <tr>
          <td>Deployment on macOS without Python</td>
          <td>⚠️</td>
          <td>✅</td>
      </tr>
      <tr>
          <td>Real-time or near real-time</td>
          <td>⚠️ (CPU bound)</td>
          <td>✅ (Metal + quantisation)</td>
      </tr>
      <tr>
          <td>Grammar/structured output</td>
          <td>Custom work required</td>
          <td>Built-in (needs more exploration)</td>
      </tr>
  </tbody>
</table>
<p>So far the balance for me looks like: use whisper.cpp for fast, repeatable inference; keep Transformers around when I need to experiment or compose models in Python.</p>
<hr>
<h2 id="4-wiring-whispercpp-into-the-existing-session-code">4. Wiring whisper.cpp into the Existing Session Code</h2>
<p>I extended the session API to support both backends. Usage now looks like this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">whisper_steer</span> <span class="kn">import</span> <span class="n">new_session</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">sess</span> <span class="o">=</span> <span class="n">new_session</span><span class="p">()</span>  <span class="c1"># reads WHISPER_STEER_* env vars</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Run via HF (local pipeline)</span>
</span></span><span class="line"><span class="cl"><span class="n">hf_res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run_asr</span><span class="p">(</span><span class="s2">&#34;audio_message&#34;</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s2">&#34;hi&#34;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;local&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Run via whisper.cpp server (defaults to http://127.0.0.1:8181)</span>
</span></span><span class="line"><span class="cl"><span class="n">server_res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run_asr</span><span class="p">(</span><span class="s2">&#34;audio_message&#34;</span><span class="p">,</span> <span class="n">language</span><span class="o">=</span><span class="s2">&#34;hi&#34;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;server&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>The CLI wrapper shares the same options:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nv">PYTHONPATH</span><span class="o">=</span>src python tools/quick_transcribe.py audio_message <span class="se">\
</span></span></span><span class="line"><span class="cl">    --language hi <span class="se">\
</span></span></span><span class="line"><span class="cl">    --backend server <span class="se">\
</span></span></span><span class="line"><span class="cl">    --no-log
</span></span></code></pre></div><p>If I don’t set <code>WHISPER_STEER_SERVER_URL</code>, the code falls back to <code>http://127.0.0.1:8181</code>. Logged results include segments and timestamps regardless of backend.</p>
<hr>
<h2 id="5-practical-todos-and-future-work">5. Practical To‑Dos and Future Work</h2>
<ol>
<li><strong>Keep whisper.cpp as the first-line inference engine on Mac.</strong> It’s faster and produces fewer artefacts out of the box. I can still parse the JSON output, run transliteration, and save the same metadata I used with HF.</li>
<li><strong>Stay with HF when I need training or cross-model experiments.</strong> LoRA/adapters aren’t an option in whisper.cpp, so Transformers remains the place for that work.</li>
<li><strong>Write down decoding settings.</strong> The biggest time sink was forgetting which clip was decoded with which language prompt or beam width. Every run now logs those parameters explicitly.</li>
<li><strong>Evaluate grammar constraints separately.</strong> whisper.cpp’s grammar tooling looks promising, but I want a dedicated test suite before trusting it in production.</li>
<li><strong>Support post-edit/transliteration in Python.</strong> The server already returns clean text; I’ll keep running transliteration (<code>indic-transliteration</code>) and domain-specific post-edit passes after the transcript comes back.</li>
</ol>
<p>That’s as far as I took things this round. If I revisit the project, grammar constraints and transliteration quality will probably be next on my list.</p>

            </div>
        </article></main>
</div>

<footer class="footer">
    <small class="footer_copyright">
        © 2026 Ravindra R. Jaju.
        Powered by <a href="https://github.com/hugo-sid/hugo-blog-awesome" target="_blank" rel="noopener">Hugo blog awesome</a>.
    </small>
</footer>


<div class="fixed-social-icons">
    <a href="https://github.com/jaju" target="_blank" rel="noopener noreferrer me"
       title="GitHub" class="social-icon">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
    </a>
    <a href="https://x.com/jaju" target="_blank" rel="noopener noreferrer me"
       title="X (Twitter)" class="social-icon">
        <svg viewBox="0 0 1200 1227" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
    <path
        d="M714.163 519.284L1160.89 0H1055.03L667.137 450.887L357.328 0H0L468.492 681.821L0 1226.37H105.866L515.491 750.218L842.672 1226.37H1200L714.137 519.284H714.163ZM569.165 687.828L521.697 619.934L144.011 79.6944H306.615L611.412 515.685L658.88 583.579L1055.08 1150.3H892.476L569.165 687.854V687.828Z"/>
</svg>
    </a>
</div>





    
    
        
    



    
    <script async src="http://localhost:1313/js/main.js" ></script>

    
        
        <script async src="http://localhost:1313/js/custom.js" ></script>
    

</body>
</html>
